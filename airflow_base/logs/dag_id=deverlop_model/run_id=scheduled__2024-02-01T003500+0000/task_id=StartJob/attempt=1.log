[2024-02-14T03:32:52.684+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T03:32:52.755+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T03:32:52.787+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2024-02-14T03:32:52.869+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): StartJob> on 2024-02-01 00:35:00+00:00
[2024-02-14T03:32:52.905+0000] {standard_task_runner.py:60} INFO - Started process 2345 to run task
[2024-02-14T03:32:52.925+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'deverlop_model', 'StartJob', 'scheduled__2024-02-01T00:35:00+00:00', '--job-id', '211', '--raw', '--subdir', 'DAGS_FOLDER/task.py', '--cfg-path', '/tmp/tmpi7txskm3']
[2024-02-14T03:32:52.948+0000] {standard_task_runner.py:88} INFO - Job 211: Subtask StartJob
[2024-02-14T03:32:53.165+0000] {task_command.py:423} INFO - Running <TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [running]> on host 6e2ff7d2ffd0
[2024-02-14T03:32:53.465+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='rtn' AIRFLOW_CTX_DAG_ID='deverlop_model' AIRFLOW_CTX_TASK_ID='StartJob' AIRFLOW_CTX_EXECUTION_DATE='2024-02-01T00:35:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-02-01T00:35:00+00:00'
[2024-02-14T03:32:53.483+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2024-02-14T03:32:53.497+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', "\n            echo StartJob && \n            if [ ! -e '/opt/***/dags/data/2024-02-14' ]; then\n                mkdir /opt/***/dags/data/2024-02-14 \n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/data' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/data\n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/model' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/model\n            fi\n        "]
[2024-02-14T03:32:53.547+0000] {subprocess.py:86} INFO - Output:
[2024-02-14T03:32:53.557+0000] {subprocess.py:93} INFO - StartJob
[2024-02-14T03:32:53.564+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2024-02-14T03:32:53.680+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=deverlop_model, task_id=StartJob, execution_date=20240201T003500, start_date=20240214T033252, end_date=20240214T033253
[2024-02-14T03:32:53.752+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-14T03:32:53.801+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-02-14T03:34:20.982+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T03:34:21.000+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T03:34:21.002+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2024-02-14T03:34:21.045+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): StartJob> on 2024-02-01 00:35:00+00:00
[2024-02-14T03:34:21.060+0000] {standard_task_runner.py:60} INFO - Started process 2441 to run task
[2024-02-14T03:34:21.065+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'deverlop_model', 'StartJob', 'scheduled__2024-02-01T00:35:00+00:00', '--job-id', '231', '--raw', '--subdir', 'DAGS_FOLDER/task.py', '--cfg-path', '/tmp/tmp33ozcks3']
[2024-02-14T03:34:21.068+0000] {standard_task_runner.py:88} INFO - Job 231: Subtask StartJob
[2024-02-14T03:34:21.203+0000] {task_command.py:423} INFO - Running <TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [running]> on host 6e2ff7d2ffd0
[2024-02-14T03:34:21.370+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='rtn' AIRFLOW_CTX_DAG_ID='deverlop_model' AIRFLOW_CTX_TASK_ID='StartJob' AIRFLOW_CTX_EXECUTION_DATE='2024-02-01T00:35:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-02-01T00:35:00+00:00'
[2024-02-14T03:34:21.373+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2024-02-14T03:34:21.381+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', "\n            echo StartJob && \n            if [ ! -e '/opt/***/dags/data/2024-02-14' ]; then\n                mkdir /opt/***/dags/data/2024-02-14 \n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/data' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/data\n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/model' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/model\n            fi\n        "]
[2024-02-14T03:34:21.415+0000] {subprocess.py:86} INFO - Output:
[2024-02-14T03:34:21.417+0000] {subprocess.py:93} INFO - StartJob
[2024-02-14T03:34:21.438+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2024-02-14T03:34:21.507+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=deverlop_model, task_id=StartJob, execution_date=20240201T003500, start_date=20240214T033420, end_date=20240214T033421
[2024-02-14T03:34:21.576+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-14T03:34:21.645+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-02-14T03:37:59.325+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T03:37:59.344+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T03:37:59.346+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2024-02-14T03:37:59.374+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): StartJob> on 2024-02-01 00:35:00+00:00
[2024-02-14T03:37:59.389+0000] {standard_task_runner.py:60} INFO - Started process 2764 to run task
[2024-02-14T03:37:59.395+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'deverlop_model', 'StartJob', 'scheduled__2024-02-01T00:35:00+00:00', '--job-id', '308', '--raw', '--subdir', 'DAGS_FOLDER/task.py', '--cfg-path', '/tmp/tmp00unmwo_']
[2024-02-14T03:37:59.403+0000] {standard_task_runner.py:88} INFO - Job 308: Subtask StartJob
[2024-02-14T03:37:59.575+0000] {task_command.py:423} INFO - Running <TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [running]> on host 6e2ff7d2ffd0
[2024-02-14T03:37:59.750+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='rtn' AIRFLOW_CTX_DAG_ID='deverlop_model' AIRFLOW_CTX_TASK_ID='StartJob' AIRFLOW_CTX_EXECUTION_DATE='2024-02-01T00:35:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-02-01T00:35:00+00:00'
[2024-02-14T03:37:59.761+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2024-02-14T03:37:59.780+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', "\n            echo StartJob && \n            if [ ! -e '/opt/***/dags/data/2024-02-14' ]; then\n                mkdir /opt/***/dags/data/2024-02-14 \n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/data' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/data\n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/model' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/model\n            fi\n        "]
[2024-02-14T03:37:59.827+0000] {subprocess.py:86} INFO - Output:
[2024-02-14T03:37:59.830+0000] {subprocess.py:93} INFO - StartJob
[2024-02-14T03:37:59.856+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2024-02-14T03:37:59.935+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=deverlop_model, task_id=StartJob, execution_date=20240201T003500, start_date=20240214T033759, end_date=20240214T033759
[2024-02-14T03:38:00.027+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-14T03:38:00.123+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-02-14T03:39:24.788+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T03:39:24.804+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T03:39:24.805+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2024-02-14T03:39:24.826+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): StartJob> on 2024-02-01 00:35:00+00:00
[2024-02-14T03:39:24.843+0000] {standard_task_runner.py:60} INFO - Started process 2967 to run task
[2024-02-14T03:39:24.851+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'deverlop_model', 'StartJob', 'scheduled__2024-02-01T00:35:00+00:00', '--job-id', '361', '--raw', '--subdir', 'DAGS_FOLDER/task.py', '--cfg-path', '/tmp/tmpn1095amq']
[2024-02-14T03:39:24.856+0000] {standard_task_runner.py:88} INFO - Job 361: Subtask StartJob
[2024-02-14T03:39:24.956+0000] {task_command.py:423} INFO - Running <TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [running]> on host 6e2ff7d2ffd0
[2024-02-14T03:39:25.125+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='rtn' AIRFLOW_CTX_DAG_ID='deverlop_model' AIRFLOW_CTX_TASK_ID='StartJob' AIRFLOW_CTX_EXECUTION_DATE='2024-02-01T00:35:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-02-01T00:35:00+00:00'
[2024-02-14T03:39:25.128+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2024-02-14T03:39:25.130+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', "\n            echo StartJob && \n            if [ ! -e '/opt/***/dags/data/2024-02-14' ]; then\n                mkdir /opt/***/dags/data/2024-02-14 \n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/data' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/data\n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/model' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/model\n            fi\n        "]
[2024-02-14T03:39:25.169+0000] {subprocess.py:86} INFO - Output:
[2024-02-14T03:39:25.171+0000] {subprocess.py:93} INFO - StartJob
[2024-02-14T03:39:25.181+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2024-02-14T03:39:25.239+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=deverlop_model, task_id=StartJob, execution_date=20240201T003500, start_date=20240214T033924, end_date=20240214T033925
[2024-02-14T03:39:25.315+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-14T03:39:25.352+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-02-14T04:09:31.023+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T04:09:31.034+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T04:09:31.034+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2024-02-14T04:09:31.057+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): StartJob> on 2024-02-01 00:35:00+00:00
[2024-02-14T04:09:31.067+0000] {standard_task_runner.py:60} INFO - Started process 4063 to run task
[2024-02-14T04:09:31.074+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'deverlop_model', 'StartJob', 'scheduled__2024-02-01T00:35:00+00:00', '--job-id', '541', '--raw', '--subdir', 'DAGS_FOLDER/task.py', '--cfg-path', '/tmp/tmp9yqss54r']
[2024-02-14T04:09:31.078+0000] {standard_task_runner.py:88} INFO - Job 541: Subtask StartJob
[2024-02-14T04:09:31.194+0000] {task_command.py:423} INFO - Running <TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [running]> on host 6e2ff7d2ffd0
[2024-02-14T04:09:31.483+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='rtn' AIRFLOW_CTX_DAG_ID='deverlop_model' AIRFLOW_CTX_TASK_ID='StartJob' AIRFLOW_CTX_EXECUTION_DATE='2024-02-01T00:35:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-02-01T00:35:00+00:00'
[2024-02-14T04:09:31.492+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2024-02-14T04:09:31.495+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', "\n            echo StartJob && \n            if [ ! -e '/opt/***/dags/data/2024-02-14' ]; then\n                mkdir /opt/***/dags/data/2024-02-14 \n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/data' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/data\n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/model' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/model\n            fi\n        "]
[2024-02-14T04:09:31.536+0000] {subprocess.py:86} INFO - Output:
[2024-02-14T04:09:31.546+0000] {subprocess.py:93} INFO - StartJob
[2024-02-14T04:09:31.565+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2024-02-14T04:09:31.613+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=deverlop_model, task_id=StartJob, execution_date=20240201T003500, start_date=20240214T040931, end_date=20240214T040931
[2024-02-14T04:09:31.664+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-14T04:09:31.713+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-02-14T04:14:27.820+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T04:14:27.833+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [queued]>
[2024-02-14T04:14:27.834+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2024-02-14T04:14:27.852+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): StartJob> on 2024-02-01 00:35:00+00:00
[2024-02-14T04:14:27.863+0000] {standard_task_runner.py:60} INFO - Started process 4226 to run task
[2024-02-14T04:14:27.866+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'deverlop_model', 'StartJob', 'scheduled__2024-02-01T00:35:00+00:00', '--job-id', '567', '--raw', '--subdir', 'DAGS_FOLDER/task.py', '--cfg-path', '/tmp/tmpk54_j_00']
[2024-02-14T04:14:27.870+0000] {standard_task_runner.py:88} INFO - Job 567: Subtask StartJob
[2024-02-14T04:14:27.934+0000] {task_command.py:423} INFO - Running <TaskInstance: deverlop_model.StartJob scheduled__2024-02-01T00:35:00+00:00 [running]> on host 6e2ff7d2ffd0
[2024-02-14T04:14:28.027+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='rtn' AIRFLOW_CTX_DAG_ID='deverlop_model' AIRFLOW_CTX_TASK_ID='StartJob' AIRFLOW_CTX_EXECUTION_DATE='2024-02-01T00:35:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-02-01T00:35:00+00:00'
[2024-02-14T04:14:28.030+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2024-02-14T04:14:28.032+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', "\n            echo StartJob && \n            if [ ! -e '/opt/***/dags/data/2024-02-14' ]; then\n                mkdir /opt/***/dags/data/2024-02-14 \n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/data' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/data\n            fi && \n            if [ ! -e '/opt/***/dags/data/2024-02-14/model' ]; then\n                mkdir /opt/***/dags/data/2024-02-14/model\n            fi\n        "]
[2024-02-14T04:14:28.049+0000] {subprocess.py:86} INFO - Output:
[2024-02-14T04:14:28.051+0000] {subprocess.py:93} INFO - StartJob
[2024-02-14T04:14:28.055+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2024-02-14T04:14:28.084+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=deverlop_model, task_id=StartJob, execution_date=20240201T003500, start_date=20240214T041427, end_date=20240214T041428
[2024-02-14T04:14:28.119+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-14T04:14:28.149+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
